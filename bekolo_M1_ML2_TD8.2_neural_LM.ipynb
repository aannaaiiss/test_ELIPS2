{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural ngram language model (naive implementation)\n",
    "\n",
    "We will implement a language model\n",
    "- at a given position i\n",
    "- it takes as input the two preceding words\n",
    "- and outputs log_probabilities for each word of the vocabulary\n",
    "\n",
    "The network will use the sum of embeddings of the two preceding words, followed by a MLP with a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27570d651d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspired by\n",
    "# voir https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "# by Robert Guthrie\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Mon', 'autre'], ','), (['autre', ','], 'mon'), ([',', 'mon'], 'semblable')]\n",
      "[([18, 17], 25), ([17, 25], 3), ([25, 3], 50)]\n"
     ]
    }
   ],
   "source": [
    "# Tiny training corpus: we will use a poem by Andrée Chedid\n",
    "# (To tokenize it just split on spaces)\n",
    "train_sent = \"\"\"\n",
    "Mon autre , mon semblable ,\n",
    "en cette chair qui se démène ,\n",
    "en ce sang qui cavalcade ,\n",
    "en ce complot du temps ,\n",
    "en cette mort qui nous guette ,\n",
    "en cette fraternité de nos fugaces vies ,\n",
    "mon semblable , mon autre ,\n",
    "là où tu es je suis .\n",
    "Le hasard ne cesse de ramener vers nos rivages \n",
    "quelques merveilles que nous n' avions pas cueillies ,\n",
    "quelques malheurs que nous n' avions pas ourdis .\n",
    "Surgi des ténèbres ou de l' éclair ,\n",
    "le hasard pose tantôt son aile sur notre épaule ,\n",
    "tantôt ses griffes dans la chair de nos vies .\n",
    "\"\"\".split()\n",
    "\n",
    "# Build list of examples:  each example is ([ word_i-2, word_i-1 ], target word)\n",
    "train_examples = [( [ train_sent[i], train_sent[i+1] ], train_sent[i+2] ) \n",
    "                  for i in range(len(train_sent) - 2)]\n",
    "\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(train_examples[:3])\n",
    "\n",
    "vocab = set(train_sent)\n",
    "w2i = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "# encode the training examples into word ids\n",
    "train_examples =  [ ( [ w2i[ex[0][0]], w2i[ex[0][1]] ], w2i[ex[1]] ) for ex in train_examples ]\n",
    "print(train_examples[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, context_size, hidden_layer_size):\n",
    "        super(NGramLanguageModel, self).__init__()\n",
    "        # the target network should work as follows:\n",
    "        #  for a single input\n",
    "        # - input =  context_size word ids (context words)\n",
    "        #    => retrieval of their embeddings\n",
    "        #    => concatenation (see the forward method below)\n",
    "        # - which provides the \"embedding layer\"\n",
    "        #    => linear combination\n",
    "        #    => reLU\n",
    "        # - which provides the \"hidden layer\"\n",
    "        #    => linear combination\n",
    "        #    => log_softmax\n",
    "        # - which provides log probabilities over the full vocabulary\n",
    "        \n",
    "        # but remember nn.Module works with a batch of inputs, not a single input\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.linear_1 = nn.Linear(context_size*embedding_size, hidden_layer_size) \n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        size = inputs.size()              # [BATCH_SIZE, CONTEXT_SIZE]\n",
    "        embeds = self.embeddings(inputs)  # [BATCH_SIZE, CONTEXT_SIZE, EMB_SIZE]\n",
    "        embeds = embeds.view(size[0], -1) # [BATCH_SIZE, CONTEXT_SIZE * EMB_SIZE] : concatenation of the 2 embeddings\n",
    "\n",
    "        # TODO: continue the forward propagation\n",
    "        #  (cf. description above of what the network should do)\n",
    "        #  to output log probabilities,\n",
    "        #  writing the shape of each additional tensor (as done above)\n",
    "        \n",
    "        out = self.linear_1(embeds) #[BATCH_SIZE,HIDDEN_LAYER_SIZE]\n",
    "        out = torch.relu(out) #[BATCH_SIZE,HIDDEN_LAYER_SIZE]\n",
    "        out = self.linear_2(out) #[BATCH_SIZE,VOCAB_SIZE]\n",
    "\n",
    "        log_probs = F.log_softmax(out, dim=1) #[BATCH_SIZE,VOCAB_SIZE]\n",
    "        \n",
    "        return log_probs\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMB_SIZE = 10\n",
    "HIDDEN_LAYER_SIZE = 128\n",
    "\n",
    "# instance of NGramLanguageModel\n",
    "my_language_model = NGramLanguageModel(len(vocab), EMB_SIZE, CONTEXT_SIZE, HIDDEN_LAYER_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.151449203491211\n",
      "8.390563011169434\n",
      "12.590409278869629\n",
      "16.662914276123047\n",
      "20.791609287261963\n",
      "25.066925525665283\n",
      "29.323373317718506\n",
      "33.68824815750122\n",
      "37.89822769165039\n",
      "42.29113149642944\n",
      "46.42962312698364\n",
      "50.497735023498535\n",
      "54.38040065765381\n",
      "58.41500520706177\n",
      "62.31788682937622\n",
      "66.70347595214844\n",
      "71.05141592025757\n",
      "75.33576583862305\n",
      "79.50575065612793\n",
      "83.73987197875977\n",
      "87.77950191497803\n",
      "92.2821536064148\n",
      "3.9292654991149902\n",
      "7.846031904220581\n",
      "11.40357518196106\n",
      "15.167227506637573\n",
      "19.04224157333374\n",
      "23.0201678276062\n",
      "26.909029006958008\n",
      "30.562878131866455\n",
      "34.37788772583008\n",
      "38.32944869995117\n",
      "42.26494264602661\n",
      "46.02215886116028\n",
      "50.152562856674194\n",
      "54.432560205459595\n",
      "57.987597942352295\n",
      "61.844754219055176\n",
      "65.2795717716217\n",
      "69.10372757911682\n",
      "73.07127261161804\n",
      "77.23184180259705\n",
      "81.30674242973328\n",
      "85.92892956733704\n",
      "3.4605212211608887\n",
      "6.974862575531006\n",
      "10.878645658493042\n",
      "14.634712219238281\n",
      "17.876873016357422\n",
      "21.528829097747803\n",
      "25.284932613372803\n",
      "28.944629669189453\n",
      "32.733460664749146\n",
      "36.374852418899536\n",
      "40.070672273635864\n",
      "43.71278238296509\n",
      "46.934967041015625\n",
      "50.21708559989929\n",
      "53.5739848613739\n",
      "57.363229751586914\n",
      "61.012447357177734\n",
      "64.91065740585327\n",
      "68.60511040687561\n",
      "72.1846182346344\n",
      "76.05718517303467\n",
      "78.04937899112701\n",
      "3.1992087364196777\n",
      "6.040746688842773\n",
      "9.087926387786865\n",
      "12.966262817382812\n",
      "16.324455976486206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.162797927856445\n",
      "23.078232526779175\n",
      "26.25992202758789\n",
      "30.246090412139893\n",
      "33.28753590583801\n",
      "36.93803644180298\n",
      "40.37679982185364\n",
      "44.00479865074158\n",
      "47.51496481895447\n",
      "50.427765130996704\n",
      "54.10487699508667\n",
      "57.12611627578735\n",
      "60.251197814941406\n",
      "63.33987474441528\n",
      "66.60127830505371\n",
      "70.17320895195007\n",
      "74.27564835548401\n",
      "2.901876926422119\n",
      "6.581538438796997\n",
      "9.544856786727905\n",
      "12.72333836555481\n",
      "15.84523057937622\n",
      "18.854832649230957\n",
      "21.917694568634033\n",
      "25.199500799179077\n",
      "28.460869312286377\n",
      "30.85666298866272\n",
      "33.55369710922241\n",
      "36.25322699546814\n",
      "38.934126138687134\n",
      "41.810322523117065\n",
      "45.059988021850586\n",
      "48.24303197860718\n",
      "51.056434631347656\n",
      "54.77275466918945\n",
      "57.96006751060486\n",
      "61.24719524383545\n",
      "65.30588150024414\n",
      "68.69584894180298\n",
      "3.064382553100586\n",
      "6.0829808712005615\n",
      "8.619710206985474\n",
      "10.826017141342163\n",
      "13.590502262115479\n",
      "15.840856552124023\n",
      "19.069714069366455\n",
      "21.84925866127014\n",
      "24.092647552490234\n",
      "27.806498050689697\n",
      "31.590261220932007\n",
      "34.73227095603943\n",
      "37.869872093200684\n",
      "40.52084970474243\n",
      "43.30073690414429\n",
      "46.30739235877991\n",
      "48.47061848640442\n",
      "52.130287647247314\n",
      "54.700780630111694\n",
      "57.781081199645996\n",
      "60.42587423324585\n",
      "63.81027698516846\n",
      "2.220472812652588\n",
      "3.821507215499878\n",
      "6.052950143814087\n",
      "8.689805507659912\n",
      "11.499861717224121\n",
      "14.531585216522217\n",
      "17.578386783599854\n",
      "20.871227264404297\n",
      "23.066660404205322\n",
      "25.3421630859375\n",
      "27.52055072784424\n",
      "29.851620197296143\n",
      "31.80491614341736\n",
      "34.18334102630615\n",
      "36.998472452163696\n",
      "39.913891315460205\n",
      "43.06188631057739\n",
      "46.03756856918335\n",
      "49.43820524215698\n",
      "51.95741868019104\n",
      "55.80498027801514\n",
      "58.417216300964355\n",
      "2.9209144115448\n",
      "5.430238962173462\n",
      "7.197614550590515\n",
      "10.175609469413757\n",
      "12.587056279182434\n",
      "15.189535021781921\n",
      "17.654326796531677\n",
      "20.83233630657196\n",
      "23.395209908485413\n",
      "25.26767659187317\n",
      "28.35448455810547\n",
      "30.376535892486572\n",
      "33.312984228134155\n",
      "35.73188591003418\n",
      "38.698094844818115\n",
      "41.53455066680908\n",
      "43.64638566970825\n",
      "45.51905870437622\n",
      "46.77684700489044\n",
      "49.19069254398346\n",
      "51.65235483646393\n",
      "52.358394265174866\n",
      "2.4229066371917725\n",
      "4.3583972454071045\n",
      "6.466737747192383\n",
      "9.316013813018799\n",
      "10.434530019760132\n",
      "13.068267822265625\n",
      "14.66194498538971\n",
      "18.281488060951233\n",
      "19.88065469264984\n",
      "21.626865029335022\n",
      "24.173630833625793\n",
      "26.52428901195526\n",
      "29.419169545173645\n",
      "31.39132261276245\n",
      "34.2730188369751\n",
      "36.34669470787048\n",
      "39.6305570602417\n",
      "40.62323588132858\n",
      "42.870892226696014\n",
      "45.70414465665817\n",
      "47.74181407690048\n",
      "48.07682865858078\n",
      "2.0032877922058105\n",
      "5.041260719299316\n",
      "7.6068174839019775\n",
      "9.774177074432373\n",
      "10.872681140899658\n",
      "13.560767412185669\n",
      "16.018678665161133\n",
      "17.896682381629944\n",
      "19.876251220703125\n",
      "21.515886068344116\n",
      "23.798335075378418\n",
      "25.988158226013184\n",
      "28.468319177627563\n",
      "30.978348970413208\n",
      "32.43883502483368\n",
      "34.022096157073975\n",
      "36.248250007629395\n",
      "37.82732319831848\n",
      "39.29947054386139\n",
      "41.12956392765045\n",
      "43.13886797428131\n",
      "47.04179108142853\n",
      "1.8110086917877197\n",
      "3.674226403236389\n",
      "5.927385449409485\n",
      "7.392739415168762\n",
      "9.185568690299988\n",
      "10.679541110992432\n",
      "12.794518947601318\n",
      "13.978130578994751\n",
      "15.277114391326904\n",
      "17.83772110939026\n",
      "19.77759075164795\n",
      "21.04121494293213\n",
      "23.158085823059082\n",
      "24.47805142402649\n",
      "25.780742287635803\n",
      "27.487669825553894\n",
      "29.23036241531372\n",
      "31.922517776489258\n",
      "34.68900680541992\n",
      "37.26018714904785\n",
      "39.60290861129761\n",
      "43.09606170654297\n",
      "1.6809078454971313\n",
      "3.261544704437256\n",
      "4.335647344589233\n",
      "5.989885449409485\n",
      "7.344475150108337\n",
      "9.580684542655945\n",
      "11.3417147397995\n",
      "13.612810492515564\n",
      "15.432657599449158\n",
      "17.378323912620544\n",
      "19.72209393978119\n",
      "21.86885416507721\n",
      "24.11311376094818\n",
      "25.759589791297913\n",
      "27.079522371292114\n",
      "28.835394740104675\n",
      "29.819347381591797\n",
      "31.264065384864807\n",
      "33.24317157268524\n",
      "34.92121934890747\n",
      "36.77052199840546\n",
      "37.30177503824234\n",
      "1.531919240951538\n",
      "3.4780423641204834\n",
      "5.110735893249512\n",
      "6.636075377464294\n",
      "7.4456236362457275\n",
      "8.667078495025635\n",
      "10.823840379714966\n",
      "11.904421329498291\n",
      "13.776515245437622\n",
      "16.023036241531372\n",
      "17.669493317604065\n",
      "19.428921699523926\n",
      "21.05269169807434\n",
      "21.773610174655914\n",
      "24.364697992801666\n",
      "26.00118178129196\n",
      "27.321941912174225\n",
      "28.722550928592682\n",
      "30.37224441766739\n",
      "32.30709511041641\n",
      "33.46228915452957\n",
      "33.95828494429588\n",
      "0.7696825265884399\n",
      "2.1667323112487793\n",
      "3.484060525894165\n",
      "4.63162088394165\n",
      "5.943223237991333\n",
      "7.861080050468445\n",
      "9.161561846733093\n",
      "10.207999587059021\n",
      "11.526755213737488\n",
      "12.621991634368896\n",
      "14.183388948440552\n",
      "15.605585098266602\n",
      "17.43564534187317\n",
      "18.63517141342163\n",
      "20.12422823905945\n",
      "21.224165081977844\n",
      "23.1060391664505\n",
      "24.94688880443573\n",
      "27.286826491355896\n",
      "28.642653942108154\n",
      "30.05707883834839\n",
      "32.38816714286804\n",
      "1.8168203830718994\n",
      "3.436185836791992\n",
      "4.230130553245544\n",
      "5.560165882110596\n",
      "7.012762546539307\n",
      "8.921507596969604\n",
      "9.871354818344116\n",
      "11.262569785118103\n",
      "12.508228778839111\n",
      "13.264281928539276\n",
      "14.699898421764374\n",
      "16.064603745937347\n",
      "16.562257081270218\n",
      "17.90182200074196\n",
      "19.196413308382034\n",
      "20.52032807469368\n",
      "21.362060576677322\n",
      "22.560859948396683\n",
      "23.39183947443962\n",
      "25.359043210744858\n",
      "26.90820810198784\n",
      "29.42573854327202\n",
      "0.9992855191230774\n",
      "1.725271224975586\n",
      "3.310715913772583\n",
      "4.447856068611145\n",
      "5.411276757717133\n",
      "6.8789785504341125\n",
      "7.575696289539337\n",
      "8.725111663341522\n",
      "9.42739188671112\n",
      "10.713948369026184\n",
      "11.742917537689209\n",
      "13.058696508407593\n",
      "14.098701000213623\n",
      "15.28197157382965\n",
      "16.99543273448944\n",
      "18.477973580360413\n",
      "19.34739398956299\n",
      "20.861892104148865\n",
      "22.21281623840332\n",
      "23.43641984462738\n",
      "24.493398070335388\n",
      "24.836791932582855\n",
      "0.9996613264083862\n",
      "2.5576579570770264\n",
      "3.526989698410034\n",
      "4.3512104749679565\n",
      "4.938084840774536\n",
      "5.727465748786926\n",
      "7.151160359382629\n",
      "8.458228945732117\n",
      "9.767183542251587\n",
      "10.56406456232071\n",
      "11.924396812915802\n",
      "13.040612757205963\n",
      "14.018087089061737\n",
      "15.31876915693283\n",
      "16.566267430782318\n",
      "18.000390589237213\n",
      "18.160031706094742\n",
      "18.979033857584\n",
      "20.051207691431046\n",
      "21.3875450193882\n",
      "22.216942578554153\n",
      "22.39730314910412\n",
      "0.6804776191711426\n",
      "1.4955723881721497\n",
      "2.4234545826911926\n",
      "3.02340030670166\n",
      "4.054871320724487\n",
      "4.913741946220398\n",
      "5.830316245555878\n",
      "7.01049941778183\n",
      "7.786750555038452\n",
      "9.570395231246948\n",
      "10.738298416137695\n",
      "11.535733342170715\n",
      "12.187989950180054\n",
      "13.534313797950745\n",
      "14.301518678665161\n",
      "15.364172220230103\n",
      "16.274051427841187\n",
      "16.88447678089142\n",
      "17.71984052658081\n",
      "19.053356051445007\n",
      "19.898038625717163\n",
      "21.133519291877747\n",
      "0.9802447557449341\n",
      "2.2460970878601074\n",
      "3.2055370211601257\n",
      "4.103033125400543\n",
      "5.240195572376251\n",
      "6.057287395000458\n",
      "6.707975447177887\n",
      "7.307507932186127\n",
      "8.481975615024567\n",
      "9.59294992685318\n",
      "10.310264527797699\n",
      "11.02005386352539\n",
      "11.655192196369171\n",
      "12.339445412158966\n",
      "12.94537204504013\n",
      "13.680300652980804\n",
      "14.701561033725739\n",
      "15.33256471157074\n",
      "16.489548206329346\n",
      "17.12335979938507\n",
      "18.16766583919525\n",
      "19.02583932876587\n",
      "0.7821685075759888\n",
      "2.0801957845687866\n",
      "2.971879243850708\n",
      "4.081473231315613\n",
      "4.7853410840034485\n",
      "5.6809499859809875\n",
      "6.489453971385956\n",
      "7.055131733417511\n",
      "8.10472971200943\n",
      "8.810596704483032\n",
      "9.327299654483795\n",
      "9.88032454252243\n",
      "10.450236439704895\n",
      "10.94513189792633\n",
      "11.686068296432495\n",
      "12.358690023422241\n",
      "12.796629846096039\n",
      "14.332370579242706\n",
      "15.490382254123688\n",
      "15.995671808719635\n",
      "16.83946865797043\n",
      "17.987198650836945\n",
      "[92.2821536064148, 85.92892956733704, 78.04937899112701, 74.27564835548401, 68.69584894180298, 63.81027698516846, 58.417216300964355, 52.358394265174866, 48.07682865858078, 47.04179108142853, 43.09606170654297, 37.30177503824234, 33.95828494429588, 32.38816714286804, 29.42573854327202, 24.836791932582855, 22.39730314910412, 21.133519291877747, 19.02583932876587, 17.987198650836945]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# to store the training losses at each epoch\n",
    "train_losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# the optimizer is the instance that will actually update the declared parameters\n",
    "optimizer = optim.SGD(my_language_model.parameters(), lr=0.05)\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "NB_EPOCHS = 20\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # shuffle data\n",
    "    shuffle(train_examples)\n",
    "    i = 0\n",
    "    while i < len(train_examples):\n",
    "        \n",
    "        batch = train_examples[i: i+BATCH_SIZE]\n",
    "        i += BATCH_SIZE\n",
    "        \n",
    "        contexts, targets = zip(*batch)\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model \n",
    "        input_tensor = torch.tensor(contexts, dtype=torch.long) # [BATCH_SIZE, CONTEXT_SIZE]\n",
    "        gold_labels = torch.tensor(targets, dtype=torch.long)   # [BATCH_SIZE]\n",
    "        \n",
    "        #TODO\n",
    "        my_language_model.zero_grad() #pourquoi fait-on ça ?\n",
    "        log_probs = my_language_model(input_tensor) #[BATCH_SIZE,VOCAB_SIZE]\n",
    "        \n",
    "        loss = loss_function(log_probs, gold_labels) \n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #FIN TODO\n",
    "    # end of handling of this batch\n",
    "    \n",
    "    train_losses.append(epoch_loss)\n",
    "print(train_losses)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To go further\n",
    "\n",
    "- display the learning curve on the train set\n",
    "- use of a dev set to tune the number of epochs using early stopping \n",
    "- handling of unknown words\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
